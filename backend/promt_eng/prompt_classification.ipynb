{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c7733e-2f50-458e-822f-8fa68ba6682e",
   "metadata": {},
   "source": [
    "## Prompt Classification Notebook\n",
    "\n",
    "This notebook is meant to test how well the chatbot can perform the classification part of the pipeline. <br>\n",
    "DISCLAIMER: We have about `$`5.00 in free API credits and are charged by how many words are inputted and output. `$`5.00 is a lot of words, probably a thousands if not hundreds of thousands so we should be okay. But preferably look to query the chatbot at an upperbound of about ~500 queries. \n",
    "\n",
    "### Insert prompts\n",
    "\n",
    "Insert prompts into `PERSONA` and `CLASSIFICATION_PROMPT` variables in the below cells. `PERSONA` will provide an identity for the chatbot, an example of it is prefilled below. The `CLASSIFICATION_PROMPT` will be prepended to every user prompt that the user queries the chatbot with. It will have to be somewhat heuristic but too general at the same time, an example is prefilled below. \n",
    "<br> <br>\n",
    "The classification prompt var is represented as a list so you can try many prompts and compare their outputs in the last step. Persona will not be that important/ impactful on the final result so we can change it sparingly. \n",
    "\n",
    "`TEMPERATURE` is defined as \"The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\" according to GPT documentation. Play with this number to see what temperature gives us the best results, I predict we want values closer to 0 since we don't want the chatbot messing around with users queries but feel free to experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93be2e9a-7091-4992-bcec-ad26cd83fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSONA: str = '''\n",
    "You are tasked with answering user queries for a hotel booking website. Your name is Nexus.\n",
    "'''\n",
    "\n",
    "CLASSIFICATION_PROMPT: list = [\n",
    "'''Given the users prompt below classify what they are talking about into the following 4 categories: account query, hotel recommendation query, conversing, misc. \n",
    "\n",
    "If they are asking about something related to their account respond with:\n",
    "{ type: ACC_QUERY }\n",
    "\n",
    "If about adding a hotel to their watchlist, booking, or getting recommendations respond with:\n",
    "{ type: HOTEL_RECC }\n",
    "\n",
    "If they are continuing a conversation with you respond with:\n",
    "{ type: CONVERSING }\n",
    "\n",
    "If they are asking about something unrelated to the above respond with:\n",
    "{ type: MISC }\n",
    "\n",
    "Answer with these formats strictly and do not waver from it. If you are unsure about how to respond then respond with { type: MISC }.\n",
    "''',\n",
    "\n",
    "]\n",
    "\n",
    "TEMPERATURE: float = 0.2 # placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "382b77b6-41bb-4b0c-99e1-eb593002a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def chat(prompt: str):\n",
    "    global PERSONA, CLASSIFICATION_PROMPT, TEMPERATURE, client\n",
    "    responses = []\n",
    "    \n",
    "    for preamble in CLASSIFICATION_PROMPT:\n",
    "        messages = [{\"role\": \"system\", \"content\": PERSONA}]\n",
    "        prompt = preamble + prompt\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=TEMPERATURE,\n",
    "        )\n",
    "\n",
    "        responses.append(completion.choices[0].message.content)\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bc4120d-8e6a-418c-9f3b-7b8b33e229b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt:  What hotels can I get for under $100?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{ type: HOTEL_RECC }\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    user_prompt = \"\"\n",
    "    while (user_prompt != \"quit\"):\n",
    "        user_prompt = input(\"Enter a prompt: \")\n",
    "        print(\"\")\n",
    "        for answer in chat(user_prompt):\n",
    "            print(answer)\n",
    "    print(\"Chat ended\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
