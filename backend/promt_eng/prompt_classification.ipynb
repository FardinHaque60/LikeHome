{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1c7733e-2f50-458e-822f-8fa68ba6682e",
   "metadata": {},
   "source": [
    "## Prompt Classification Notebook\n",
    "\n",
    "This notebook is meant to test how well the chatbot can perform the classification part of the pipeline. <br> <br>\n",
    "DISCLAIMER: We have about `$`5.00 in free API credits and are charged by how many words are inputted and output. `$`5.00 is a lot of words, probably a thousands if not hundreds of thousands so we should be okay. But preferably look to query the chatbot at an upperbound of about ~500 queries. \n",
    "\n",
    "### Insert prompts\n",
    "\n",
    "Update `PERSONA`, `CLASSIFICATION_PROMPT`, `DATA_REQ`, and `TEMPERATURE` below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484fa2f-a6d7-43ef-a84a-0225f734c16a",
   "metadata": {},
   "source": [
    "Set `PERSONA`variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93be2e9a-7091-4992-bcec-ad26cd83fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO UPDATE\n",
    "# this is the identity of the bot, gives it some context for what it will do etc.\n",
    "PERSONA: str = '''You are tasked with answering user queries for a hotel booking website. Your name is Nexus.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a28eddd-92c0-4e47-ad12-dacc3abf20bf",
   "metadata": {},
   "source": [
    "`CLASSIFICATION_PROMPT` is a list of prompts. Add several prompts into the list to test them simultaneously, the output at the end will be for its respective prompt.\n",
    "<br> `DATA_REQ` defines the format you want GPT to respond in. It is appended to each classification prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51772d52-f911-44e0-a224-a97be704e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO UPDATE\n",
    "# this prompt is prepended to the users query everytime they send a message so dont make it too specific or generic.\n",
    "CLASSIFICATION_PROMPT: list = [\n",
    "'''Given the users prompt below classify what they are talking about into the following 4 categories: \n",
    "account query, hotel recommendation query, conversing, misc.''',\n",
    "\n",
    "'''Using the users prompt below, you are tasked with determing what the user wants. Categorize their query as either an account query,\n",
    "hotel related question, continuing a conversation with you, or unrelated/ misc''',\n",
    "\n",
    "]\n",
    "\n",
    "# TODO UPDATE\n",
    "# This part is appended to every classification prompt, it shows what format the answer should be in\n",
    "DATA_REQ = '''\n",
    "If they are asking about something related to their account respond with:\n",
    "{ \"type\": \"ACC_QUERY\" }\n",
    "\n",
    "If asking about adding a hotel to their watchlist, booking, or getting recommendations respond with. \n",
    "If the user does not provide enough information for you to fill out all of the data fields, then fill then in with \"NULL\". \n",
    "Make sure you follow JSON format so things are in quotes especially \"NULL\":\n",
    "{ \n",
    "    \"type\": \"HOTEL_RECC\",\n",
    "    \"data\": {\n",
    "        \"location\": str,\n",
    "        \"check_in\": str,\n",
    "        \"check_out\": str,\n",
    "        \"rooms\": int,\n",
    "        \"adults\": int,\n",
    "        \"children\": int,\n",
    "        \"radius\": int,\n",
    "        \"min_price\": int,\n",
    "        \"max_price\": int,\n",
    "    }\n",
    "}\n",
    "\n",
    "If they are continuing a conversation with you regarding booking a hotel, respond with. Update the data with what you knew previously\n",
    "and what new information they give:\n",
    "{ \n",
    "    \"type\": \"CONVERSING\"\n",
    "    \"data\": {\n",
    "        \"location\": str,\n",
    "        \"check_in\": str,\n",
    "        \"check_out\": str,\n",
    "        \"rooms\": int,\n",
    "        \"adults\": int,\n",
    "        \"children\": int,\n",
    "        \"radius\": int,\n",
    "        \"min_price\": int,\n",
    "        \"max_price\": int,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "If they are asking about something unrelated to the above politely generate a fitting response. For example if they are asking about\n",
    "something not related to their LikeHome account then say you cannot help with that. If they are thanking you for helping them\n",
    "then respond accordingly.\n",
    "\n",
    "Answer with these instructions strictly and do not waver from it.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a0f149-bf3d-4fd2-a1a2-e00ebf938d1d",
   "metadata": {},
   "source": [
    "Set `TEMPERATURE` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe40a75-9be6-46ca-9bf2-6517f82aef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO UPDATE\n",
    "# this variable represents how \"creative\" gpt's responses are. Values closer to 0 are more straightforward and values closer to 1 are more creative\n",
    "# we probably want values closer the bot doesnt hallucinate but experiment.\n",
    "TEMPERATURE: float = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19582c0",
   "metadata": {},
   "source": [
    "### See prompts\n",
    "\n",
    "Run the cell below to see what prompts, verbatim GPT will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea065489",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Persona: {PERSONA}\\n\")\n",
    "\n",
    "print(f\"Temperature: {TEMPERATURE} \\n\")\n",
    "\n",
    "classify_copy = CLASSIFICATION_PROMPT.copy()\n",
    "\n",
    "print(\"Classification prompts that are going to be passed:\\n\")\n",
    "for i in range(len(CLASSIFICATION_PROMPT)):\n",
    "    CLASSIFICATION_PROMPT[i] += DATA_REQ\n",
    "    print(f\"Prompt {i}: {CLASSIFICATION_PROMPT[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639a7ca-b642-4dad-afda-11206650d38b",
   "metadata": {},
   "source": [
    "### Set-Up functions\n",
    "\n",
    "Just run the cell below to set up the API request to GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b77b6-41bb-4b0c-99e1-eb593002a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "client = OpenAI()\n",
    "conversation = []\n",
    "# initialize conversations with persona\n",
    "for i in range(len(CLASSIFICATION_PROMPT)):\n",
    "    conversation.append([{\"role\": \"system\", \"content\": PERSONA}])\n",
    "\n",
    "def chat(prompt: str):\n",
    "    global PERSONA, CLASSIFICATION_PROMPT, TEMPERATURE, client, conversation\n",
    "    temp_responses = []\n",
    "    \n",
    "    for i in range(len(CLASSIFICATION_PROMPT)):\n",
    "        # prompt = CLASSIFICATION_PROMPT[i] + prompt\n",
    "        # TODO see if its better to seperate preamble as system or keep with user\n",
    "        conversation[i].append({\"role\": \"system\", \"content\": CLASSIFICATION_PROMPT[i]})\n",
    "        conversation[i].append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=conversation[i],\n",
    "            temperature=TEMPERATURE,\n",
    "        )\n",
    "        response = completion.choices[0].message.content\n",
    "        temp_responses.append(response)\n",
    "\n",
    "        # TODO look into if storing gpt response for testing is neccessary\n",
    "        conversation[i].append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    return temp_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a2a75",
   "metadata": {},
   "source": [
    "### Run \n",
    "\n",
    "Run the cell below to begin having a conversation with GPT. A textbox will a appear and a table will be made with GPTs outputs and which prompt was used for it. Type `quit` to end the conversation.\n",
    "\n",
    "Criteria to judge outputs:\n",
    "* Make sure if the user has typos in the prompt GPT fixes them in the response\n",
    "* Make sure GPT follows the format (i.e. { type: , data: } format stricty. We converting GPT's response into a python variable so if it wavers python can't convert it to a variable\n",
    "* Make sure it can get data when its presented in different ways. Example: Someone might want to book a room 2 people but might it say it like \"book a room for me and my child\" see if it can realize that means 1 adult, 1 child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4120d-8e6a-418c-9f3b-7b8b33e229b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    user_prompt = \"\"\n",
    "    while (True):\n",
    "        user_prompt = input(\"Enter a prompt: \")\n",
    "        if (user_prompt == \"quit\"):\n",
    "            print(\"Chat ended\")\n",
    "            break\n",
    "        print(\"\")\n",
    "        responses = chat(user_prompt)\n",
    "        df = pd.DataFrame({\n",
    "            \"Prompt\": classify_copy,\n",
    "            \"Response\": responses,\n",
    "        })\n",
    "        df_styled = df.style.set_table_styles([\n",
    "            {\n",
    "                'selector': 'table',\n",
    "                'props': [('width', '100%'), ('overflow', 'hidden')]  \n",
    "            },\n",
    "            {\n",
    "                'selector': 'td',  \n",
    "                'props': [\n",
    "                    ('max-height', '100px'),\n",
    "                    ('max-width', '650px'),\n",
    "                    ('overflow', 'auto'), \n",
    "                    ('white-space', 'pre'), \n",
    "                    ('text-align', 'left'), \n",
    "                    ('padding', '5px'),     \n",
    "                    ('border', '1px solid black') \n",
    "                ]\n",
    "            }\n",
    "        ])\n",
    "        display(df_styled)\n",
    "        print(\"\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
